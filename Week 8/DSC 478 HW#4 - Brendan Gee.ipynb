{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.)\n",
    "Load in the image data matrix (with rows as images and columns as features). Also load in the numeric class labels from the segmentation class file. Using your favorite method (e.g., sklearn's min-max scaler), perform min-max normalization on the data matrix so that each feature is scaled to [0,1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      0      1   2    3    4         5         6         7         8   \\\n",
       " 0  110.0  189.0   9  0.0  0.0  1.000000  0.666667  1.222222  1.186342   \n",
       " 1   86.0  187.0   9  0.0  0.0  1.111111  0.720082  1.444444  0.750309   \n",
       " 2  225.0  244.0   9  0.0  0.0  3.388889  2.195113  3.000000  1.520234   \n",
       " 3   47.0  232.0   9  0.0  0.0  1.277778  1.254621  1.000000  0.894427   \n",
       " 4   97.0  186.0   9  0.0  0.0  1.166667  0.691215  1.166667  1.005540   \n",
       " \n",
       "           9          10         11         12        13         14         15  \\\n",
       " 0  12.925926  10.888889   9.222222  18.666668 -6.111111 -11.111111  17.222221   \n",
       " 1  13.740741  11.666667  10.333334  19.222221 -6.222222 -10.222222  16.444445   \n",
       " 2  12.259259  10.333334   9.333334  17.111110 -5.777778  -8.777778  14.555555   \n",
       " 3  12.703704  11.000000   9.000000  18.111110 -5.111111 -11.111111  16.222221   \n",
       " 4  15.592592  13.888889  11.777778  21.111110 -5.111111 -11.444445  16.555555   \n",
       " \n",
       "           16        17        18  \n",
       " 0  18.666668  0.508139  1.910864  \n",
       " 1  19.222221  0.463329  1.941465  \n",
       " 2  17.111110  0.480149  1.987902  \n",
       " 3  18.111110  0.500966  1.875362  \n",
       " 4  21.111110  0.442661  1.863654  ,\n",
       " (2100, 19))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in data matrix\n",
    "df = pd.read_csv('segmentation_data.txt', header=None)\n",
    "df.head(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REGION-CENTROID-COL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REGION-CENTROID-ROW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REGION-PIXEL-COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHORT-LINE-DENSITY-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHORT-LINE-DENSITY-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "0   REGION-CENTROID-COL\n",
       "1   REGION-CENTROID-ROW\n",
       "2    REGION-PIXEL-COUNT\n",
       "3  SHORT-LINE-DENSITY-5\n",
       "4  SHORT-LINE-DENSITY-2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in feature labels\n",
    "col_labels = pd.read_csv('segmentation_names.txt', header=None)\n",
    "col_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION-CENTROID-COL</th>\n",
       "      <th>REGION-CENTROID-ROW</th>\n",
       "      <th>REGION-PIXEL-COUNT</th>\n",
       "      <th>SHORT-LINE-DENSITY-5</th>\n",
       "      <th>SHORT-LINE-DENSITY-2</th>\n",
       "      <th>VEDGE-MEAN</th>\n",
       "      <th>VEDGE-SD</th>\n",
       "      <th>HEDGE-MEAN</th>\n",
       "      <th>HEDGE-SD</th>\n",
       "      <th>INTENSITY-MEAN</th>\n",
       "      <th>RAWRED-MEAN</th>\n",
       "      <th>RAWBLUE-MEAN</th>\n",
       "      <th>RAWGREEN-MEAN</th>\n",
       "      <th>EXRED-MEAN</th>\n",
       "      <th>EXBLUE-MEAN</th>\n",
       "      <th>EXGREEN-MEAN</th>\n",
       "      <th>VALUE-MEAN</th>\n",
       "      <th>SATURATION-MEAN</th>\n",
       "      <th>HUE-MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>1.186342</td>\n",
       "      <td>12.925926</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>18.666668</td>\n",
       "      <td>-6.111111</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>17.222221</td>\n",
       "      <td>18.666668</td>\n",
       "      <td>0.508139</td>\n",
       "      <td>1.910864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.720082</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>0.750309</td>\n",
       "      <td>13.740741</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>10.333334</td>\n",
       "      <td>19.222221</td>\n",
       "      <td>-6.222222</td>\n",
       "      <td>-10.222222</td>\n",
       "      <td>16.444445</td>\n",
       "      <td>19.222221</td>\n",
       "      <td>0.463329</td>\n",
       "      <td>1.941465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.388889</td>\n",
       "      <td>2.195113</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.520234</td>\n",
       "      <td>12.259259</td>\n",
       "      <td>10.333334</td>\n",
       "      <td>9.333334</td>\n",
       "      <td>17.111110</td>\n",
       "      <td>-5.777778</td>\n",
       "      <td>-8.777778</td>\n",
       "      <td>14.555555</td>\n",
       "      <td>17.111110</td>\n",
       "      <td>0.480149</td>\n",
       "      <td>1.987902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>1.254621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>12.703704</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.111110</td>\n",
       "      <td>-5.111111</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>16.222221</td>\n",
       "      <td>18.111110</td>\n",
       "      <td>0.500966</td>\n",
       "      <td>1.875362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.691215</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.005540</td>\n",
       "      <td>15.592592</td>\n",
       "      <td>13.888889</td>\n",
       "      <td>11.777778</td>\n",
       "      <td>21.111110</td>\n",
       "      <td>-5.111111</td>\n",
       "      <td>-11.444445</td>\n",
       "      <td>16.555555</td>\n",
       "      <td>21.111110</td>\n",
       "      <td>0.442661</td>\n",
       "      <td>1.863654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0  REGION-CENTROID-COL  REGION-CENTROID-ROW  REGION-PIXEL-COUNT  \\\n",
       "0                110.0                189.0                   9   \n",
       "1                 86.0                187.0                   9   \n",
       "2                225.0                244.0                   9   \n",
       "3                 47.0                232.0                   9   \n",
       "4                 97.0                186.0                   9   \n",
       "\n",
       "0  SHORT-LINE-DENSITY-5  SHORT-LINE-DENSITY-2  VEDGE-MEAN  VEDGE-SD  \\\n",
       "0                   0.0                   0.0    1.000000  0.666667   \n",
       "1                   0.0                   0.0    1.111111  0.720082   \n",
       "2                   0.0                   0.0    3.388889  2.195113   \n",
       "3                   0.0                   0.0    1.277778  1.254621   \n",
       "4                   0.0                   0.0    1.166667  0.691215   \n",
       "\n",
       "0  HEDGE-MEAN  HEDGE-SD  INTENSITY-MEAN  RAWRED-MEAN  RAWBLUE-MEAN  \\\n",
       "0    1.222222  1.186342       12.925926    10.888889      9.222222   \n",
       "1    1.444444  0.750309       13.740741    11.666667     10.333334   \n",
       "2    3.000000  1.520234       12.259259    10.333334      9.333334   \n",
       "3    1.000000  0.894427       12.703704    11.000000      9.000000   \n",
       "4    1.166667  1.005540       15.592592    13.888889     11.777778   \n",
       "\n",
       "0  RAWGREEN-MEAN  EXRED-MEAN  EXBLUE-MEAN  EXGREEN-MEAN  VALUE-MEAN  \\\n",
       "0      18.666668   -6.111111   -11.111111     17.222221   18.666668   \n",
       "1      19.222221   -6.222222   -10.222222     16.444445   19.222221   \n",
       "2      17.111110   -5.777778    -8.777778     14.555555   17.111110   \n",
       "3      18.111110   -5.111111   -11.111111     16.222221   18.111110   \n",
       "4      21.111110   -5.111111   -11.444445     16.555555   21.111110   \n",
       "\n",
       "0  SATURATION-MEAN  HUE-MEAN  \n",
       "0         0.508139  1.910864  \n",
       "1         0.463329  1.941465  \n",
       "2         0.480149  1.987902  \n",
       "3         0.500966  1.875362  \n",
       "4         0.442661  1.863654  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assign labels to df\n",
    "df.columns = col_labels[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       0  1\n",
       " 0  GRASS  0\n",
       " 1  GRASS  0\n",
       " 2  GRASS  0\n",
       " 3  GRASS  0\n",
       " 4  GRASS  0,\n",
       " (2100, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in class labels\n",
    "df_target = pd.read_csv('segmentation_classes.txt', sep='\\t', header=None)\n",
    "df_target.head(), df_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min-max scaler on df\n",
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(df)\n",
    "\n",
    "df_norm = min_max_scaler.transform(df)\n",
    "df_norm = pd.DataFrame(df_norm, columns=df.columns, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION-CENTROID-COL</th>\n",
       "      <th>REGION-CENTROID-ROW</th>\n",
       "      <th>REGION-PIXEL-COUNT</th>\n",
       "      <th>SHORT-LINE-DENSITY-5</th>\n",
       "      <th>SHORT-LINE-DENSITY-2</th>\n",
       "      <th>VEDGE-MEAN</th>\n",
       "      <th>VEDGE-SD</th>\n",
       "      <th>HEDGE-MEAN</th>\n",
       "      <th>HEDGE-SD</th>\n",
       "      <th>INTENSITY-MEAN</th>\n",
       "      <th>RAWRED-MEAN</th>\n",
       "      <th>RAWBLUE-MEAN</th>\n",
       "      <th>RAWGREEN-MEAN</th>\n",
       "      <th>EXRED-MEAN</th>\n",
       "      <th>EXBLUE-MEAN</th>\n",
       "      <th>EXGREEN-MEAN</th>\n",
       "      <th>VALUE-MEAN</th>\n",
       "      <th>SATURATION-MEAN</th>\n",
       "      <th>HUE-MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.430830</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034221</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.027329</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.090111</td>\n",
       "      <td>0.079417</td>\n",
       "      <td>0.061119</td>\n",
       "      <td>0.130943</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.014118</td>\n",
       "      <td>0.872865</td>\n",
       "      <td>0.123711</td>\n",
       "      <td>0.508139</td>\n",
       "      <td>0.831849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.335968</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038023</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.032298</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.095791</td>\n",
       "      <td>0.085089</td>\n",
       "      <td>0.068483</td>\n",
       "      <td>0.134840</td>\n",
       "      <td>0.729478</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.859583</td>\n",
       "      <td>0.127393</td>\n",
       "      <td>0.463329</td>\n",
       "      <td>0.836986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.885375</td>\n",
       "      <td>0.970833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115970</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.067081</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.085463</td>\n",
       "      <td>0.075365</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.120031</td>\n",
       "      <td>0.736940</td>\n",
       "      <td>0.038824</td>\n",
       "      <td>0.827324</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>0.480149</td>\n",
       "      <td>0.844782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.920833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043726</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.022360</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.088562</td>\n",
       "      <td>0.080227</td>\n",
       "      <td>0.059647</td>\n",
       "      <td>0.127046</td>\n",
       "      <td>0.748134</td>\n",
       "      <td>0.014118</td>\n",
       "      <td>0.855787</td>\n",
       "      <td>0.120029</td>\n",
       "      <td>0.500966</td>\n",
       "      <td>0.825889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.379447</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039924</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.108701</td>\n",
       "      <td>0.101297</td>\n",
       "      <td>0.078056</td>\n",
       "      <td>0.148090</td>\n",
       "      <td>0.748134</td>\n",
       "      <td>0.010588</td>\n",
       "      <td>0.861480</td>\n",
       "      <td>0.139912</td>\n",
       "      <td>0.442661</td>\n",
       "      <td>0.823924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0  REGION-CENTROID-COL  REGION-CENTROID-ROW  REGION-PIXEL-COUNT  \\\n",
       "0             0.430830             0.741667                 0.0   \n",
       "1             0.335968             0.733333                 0.0   \n",
       "2             0.885375             0.970833                 0.0   \n",
       "3             0.181818             0.920833                 0.0   \n",
       "4             0.379447             0.729167                 0.0   \n",
       "\n",
       "0  SHORT-LINE-DENSITY-5  SHORT-LINE-DENSITY-2  VEDGE-MEAN  VEDGE-SD  \\\n",
       "0                   0.0                   0.0    0.034221  0.000672   \n",
       "1                   0.0                   0.0    0.038023  0.000726   \n",
       "2                   0.0                   0.0    0.115970  0.002213   \n",
       "3                   0.0                   0.0    0.043726  0.001265   \n",
       "4                   0.0                   0.0    0.039924  0.000697   \n",
       "\n",
       "0  HEDGE-MEAN  HEDGE-SD  INTENSITY-MEAN  RAWRED-MEAN  RAWBLUE-MEAN  \\\n",
       "0    0.027329  0.000856        0.090111     0.079417      0.061119   \n",
       "1    0.032298  0.000541        0.095791     0.085089      0.068483   \n",
       "2    0.067081  0.001097        0.085463     0.075365      0.061856   \n",
       "3    0.022360  0.000645        0.088562     0.080227      0.059647   \n",
       "4    0.026087  0.000725        0.108701     0.101297      0.078056   \n",
       "\n",
       "0  RAWGREEN-MEAN  EXRED-MEAN  EXBLUE-MEAN  EXGREEN-MEAN  VALUE-MEAN  \\\n",
       "0       0.130943    0.731343     0.014118      0.872865    0.123711   \n",
       "1       0.134840    0.729478     0.023529      0.859583    0.127393   \n",
       "2       0.120031    0.736940     0.038824      0.827324    0.113402   \n",
       "3       0.127046    0.748134     0.014118      0.855787    0.120029   \n",
       "4       0.148090    0.748134     0.010588      0.861480    0.139912   \n",
       "\n",
       "0  SATURATION-MEAN  HUE-MEAN  \n",
       "0         0.508139  0.831849  \n",
       "1         0.463329  0.836986  \n",
       "2         0.480149  0.844782  \n",
       "3         0.500966  0.825889  \n",
       "4         0.442661  0.823924  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    }
   ],
   "source": [
    "print(df['REGION-PIXEL-COUNT'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.)\n",
    "Using the Kmeans implementation in scikit-learn, perform clustering on the image data (use K = 7 in your clustering so that later we can compare the clusters to the 7 pre-assigned image classes). Print the cluster centroids (use some formatting so that they are visually understandable). To evaluate your clusters, first perform Silhouette analysis on the clusters (compute Silhouette values for all instances in the data, and then compute the overall mean Silhouette value; optionally, you can provide a visualization of the Silhouettes). Next, compare your 7 clusters to the 7 pre-assigned classes by computing the Completeness and Homogeneity values of the generated clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans, fit data and \"predict\" the cluster assignment\n",
    "kmeans = KMeans(n_clusters=7, max_iter=500)\n",
    "kmeans.fit(df_norm)\n",
    "clusters = kmeans.predict(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 3, 3, 0], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION-CENTROID-COL</th>\n",
       "      <th>REGION-CENTROID-ROW</th>\n",
       "      <th>REGION-PIXEL-COUNT</th>\n",
       "      <th>SHORT-LINE-DENSITY-5</th>\n",
       "      <th>SHORT-LINE-DENSITY-2</th>\n",
       "      <th>VEDGE-MEAN</th>\n",
       "      <th>VEDGE-SD</th>\n",
       "      <th>HEDGE-MEAN</th>\n",
       "      <th>HEDGE-SD</th>\n",
       "      <th>INTENSITY-MEAN</th>\n",
       "      <th>RAWRED-MEAN</th>\n",
       "      <th>RAWBLUE-MEAN</th>\n",
       "      <th>RAWGREEN-MEAN</th>\n",
       "      <th>EXRED-MEAN</th>\n",
       "      <th>EXBLUE-MEAN</th>\n",
       "      <th>EXGREEN-MEAN</th>\n",
       "      <th>VALUE-MEAN</th>\n",
       "      <th>SATURATION-MEAN</th>\n",
       "      <th>HUE-MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.256103</td>\n",
       "      <td>0.393468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.019118</td>\n",
       "      <td>0.077343</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.060574</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>0.148187</td>\n",
       "      <td>0.138085</td>\n",
       "      <td>0.185160</td>\n",
       "      <td>0.118539</td>\n",
       "      <td>0.716906</td>\n",
       "      <td>0.344014</td>\n",
       "      <td>0.355458</td>\n",
       "      <td>0.185413</td>\n",
       "      <td>0.411986</td>\n",
       "      <td>0.201890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.513994</td>\n",
       "      <td>0.808937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077441</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.054474</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.046335</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.108790</td>\n",
       "      <td>0.091403</td>\n",
       "      <td>0.092414</td>\n",
       "      <td>0.142676</td>\n",
       "      <td>0.679161</td>\n",
       "      <td>0.079002</td>\n",
       "      <td>0.821287</td>\n",
       "      <td>0.134901</td>\n",
       "      <td>0.414491</td>\n",
       "      <td>0.892333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.535099</td>\n",
       "      <td>0.150167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.030228</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.026766</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.823246</td>\n",
       "      <td>0.779716</td>\n",
       "      <td>0.894170</td>\n",
       "      <td>0.788761</td>\n",
       "      <td>0.270665</td>\n",
       "      <td>0.666373</td>\n",
       "      <td>0.289386</td>\n",
       "      <td>0.894170</td>\n",
       "      <td>0.211804</td>\n",
       "      <td>0.125066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.770674</td>\n",
       "      <td>0.425215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013978</td>\n",
       "      <td>0.022581</td>\n",
       "      <td>0.040237</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.023122</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.041138</td>\n",
       "      <td>0.035005</td>\n",
       "      <td>0.058340</td>\n",
       "      <td>0.028766</td>\n",
       "      <td>0.778473</td>\n",
       "      <td>0.223939</td>\n",
       "      <td>0.486509</td>\n",
       "      <td>0.059295</td>\n",
       "      <td>0.538181</td>\n",
       "      <td>0.243969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.302506</td>\n",
       "      <td>0.530862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052260</td>\n",
       "      <td>0.046610</td>\n",
       "      <td>0.100817</td>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.083972</td>\n",
       "      <td>0.011043</td>\n",
       "      <td>0.400608</td>\n",
       "      <td>0.370347</td>\n",
       "      <td>0.472461</td>\n",
       "      <td>0.353036</td>\n",
       "      <td>0.497146</td>\n",
       "      <td>0.570882</td>\n",
       "      <td>0.213054</td>\n",
       "      <td>0.472461</td>\n",
       "      <td>0.302263</td>\n",
       "      <td>0.163879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.254169</td>\n",
       "      <td>0.459974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026256</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.037274</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.027874</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.026013</td>\n",
       "      <td>0.017925</td>\n",
       "      <td>0.042306</td>\n",
       "      <td>0.016504</td>\n",
       "      <td>0.769800</td>\n",
       "      <td>0.216011</td>\n",
       "      <td>0.508117</td>\n",
       "      <td>0.043295</td>\n",
       "      <td>0.801687</td>\n",
       "      <td>0.181153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.750696</td>\n",
       "      <td>0.534564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.114419</td>\n",
       "      <td>0.019301</td>\n",
       "      <td>0.109240</td>\n",
       "      <td>0.017999</td>\n",
       "      <td>0.300955</td>\n",
       "      <td>0.279908</td>\n",
       "      <td>0.352738</td>\n",
       "      <td>0.265920</td>\n",
       "      <td>0.592572</td>\n",
       "      <td>0.451124</td>\n",
       "      <td>0.309158</td>\n",
       "      <td>0.352822</td>\n",
       "      <td>0.302342</td>\n",
       "      <td>0.164764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0  REGION-CENTROID-COL  REGION-CENTROID-ROW  REGION-PIXEL-COUNT  \\\n",
       "0             0.256103             0.393468                 0.0   \n",
       "1             0.513994             0.808937                 0.0   \n",
       "2             0.535099             0.150167                 0.0   \n",
       "3             0.770674             0.425215                 0.0   \n",
       "4             0.302506             0.530862                 0.0   \n",
       "5             0.254169             0.459974                 0.0   \n",
       "6             0.750696             0.534564                 0.0   \n",
       "\n",
       "0  SHORT-LINE-DENSITY-5  SHORT-LINE-DENSITY-2  VEDGE-MEAN  VEDGE-SD  \\\n",
       "0              0.074510              0.019118    0.077343  0.004100   \n",
       "1              0.077441              0.005051    0.054474  0.001407   \n",
       "2              0.027778              0.001667    0.030228  0.000543   \n",
       "3              0.013978              0.022581    0.040237  0.002989   \n",
       "4              0.052260              0.046610    0.100817  0.009420   \n",
       "5              0.026256              0.013699    0.037274  0.002364   \n",
       "6              0.040000              0.038462    0.114419  0.019301   \n",
       "\n",
       "0  HEDGE-MEAN  HEDGE-SD  INTENSITY-MEAN  RAWRED-MEAN  RAWBLUE-MEAN  \\\n",
       "0    0.060574  0.004967        0.148187     0.138085      0.185160   \n",
       "1    0.046335  0.001401        0.108790     0.091403      0.092414   \n",
       "2    0.026766  0.000587        0.823246     0.779716      0.894170   \n",
       "3    0.023122  0.002088        0.041138     0.035005      0.058340   \n",
       "4    0.083972  0.011043        0.400608     0.370347      0.472461   \n",
       "5    0.027874  0.002017        0.026013     0.017925      0.042306   \n",
       "6    0.109240  0.017999        0.300955     0.279908      0.352738   \n",
       "\n",
       "0  RAWGREEN-MEAN  EXRED-MEAN  EXBLUE-MEAN  EXGREEN-MEAN  VALUE-MEAN  \\\n",
       "0       0.118539    0.716906     0.344014      0.355458    0.185413   \n",
       "1       0.142676    0.679161     0.079002      0.821287    0.134901   \n",
       "2       0.788761    0.270665     0.666373      0.289386    0.894170   \n",
       "3       0.028766    0.778473     0.223939      0.486509    0.059295   \n",
       "4       0.353036    0.497146     0.570882      0.213054    0.472461   \n",
       "5       0.016504    0.769800     0.216011      0.508117    0.043295   \n",
       "6       0.265920    0.592572     0.451124      0.309158    0.352822   \n",
       "\n",
       "0  SATURATION-MEAN  HUE-MEAN  \n",
       "0         0.411986  0.201890  \n",
       "1         0.414491  0.892333  \n",
       "2         0.211804  0.125066  \n",
       "3         0.538181  0.243969  \n",
       "4         0.302263  0.163879  \n",
       "5         0.801687  0.181153  \n",
       "6         0.302342  0.164764  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate and print centroids\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=df.columns)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure the quality of clustering, Silhouette values\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57202831 0.56064636 0.46584172 0.49522097 0.57151852 0.56037254\n",
      " 0.54213796 0.41254281 0.51968142 0.46733032 0.48661677 0.49108474\n",
      " 0.58463969 0.56222519 0.37949564 0.53083575 0.54919193 0.42227935\n",
      " 0.41618572 0.40389039]\n"
     ]
    }
   ],
   "source": [
    "silhouettes = metrics.silhouette_samples(df_norm, clusters)\n",
    "print(silhouettes[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.332066475286672\n"
     ]
    }
   ],
   "source": [
    "#average silhouette score, closer to 1 is better, range -1 to 1\n",
    "print(silhouettes.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot silhouette data\n",
    "def plot_silhouettes(data, clusters):\n",
    "    \n",
    "    from matplotlib import cm\n",
    "    from sklearn.metrics import silhouette_samples\n",
    "    \n",
    "    cluster_labels = np.unique(clusters)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = metrics.silhouette_samples(data, clusters, metric='euclidean')\n",
    "    c_ax_lower, c_ax_upper = 0,0\n",
    "    cticks = []\n",
    "    \n",
    "    for i, k in enumerate(cluster_labels):\n",
    "        c_silhouette_vals = silhouette_vals[clusters == k]\n",
    "        c_silhouette_vals.sort()\n",
    "        c_ax_upper += len(c_silhouette_vals)\n",
    "        color = cm.jet(float(i) / n_clusters)\n",
    "        plt.barh(range(c_ax_lower, c_ax_upper), c_silhouette_vals, height=1.0,\n",
    "               edgecolor='none', color=color)\n",
    "        \n",
    "        cticks.append((c_ax_lower + c_ax_upper) / 2)\n",
    "        c_ax_lower += len(c_silhouette_vals)\n",
    "    silhouette_avg = np.mean(silhouette_vals)\n",
    "    plt.axvline(silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    \n",
    "    plt.yticks(cticks, cluster_labels)\n",
    "    plt.ylabel(\"Cluster\")\n",
    "    plt.xlabel(\"silhouette coefficient\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_silhouettes(df_norm, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import completeness_score, homogeneity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness Score: 0.6131870124853012\n",
      "Homogenity Score: 0.6115021163370863\n"
     ]
    }
   ],
   "source": [
    "#calculate homogenity and completeness scores\n",
    "print(f\"Completeness Score: {completeness_score(df_target[1],clusters)}\")\n",
    "print(f\"Homogenity Score: {homogeneity_score(df_target[1],clusters)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "From our mean silhouette score, we get a value of .332, which isn't a great score to get, as we want to score as close to 1 as possible. We further validate this by plotting the silhouette scores for each observation, and see that there are 2-3 clusters classified decently (cluster 1, 2, 5), while the rest are scoring pretty far below the average and even negative silhouette scores. Then, we calculate the completeness and homogenity scores by comparing the target classification with our predicted clusters. We get completeness & homogenity scores of .613 and .611 respectively, indicating that our separation between clusters and cohesion within clusters isn't great either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.)\n",
    "Do your own experiments with the number of clusters to see if a different value of K results in more cohesive clustering based on Silhouette analysis. Please do not provide all your clustering results, but you should include the best result according to your analysis and provide a brief discussion of why this particular clustering was selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to check best mean silhouette value for given k\n",
    "def silhouette_calc(data,N):\n",
    "    '''takes in data and a value for N and checks that number of k and returns max silhouette val w/ k'''\n",
    "    from sklearn import metrics\n",
    "    \n",
    "    res = {}\n",
    "    \n",
    "    for i in range(2,N+1):\n",
    "        kmeans = KMeans(n_clusters=i, max_iter=500) #kmeans for i# of clusters\n",
    "        kmeans.fit(data) #fit data\n",
    "        clusters = kmeans.predict(data) #assign clusters\n",
    "        silhouettes = metrics.silhouette_samples(data, clusters) #calc silhouette scores\n",
    "        res[i] = silhouettes.mean() #stores silhouette score\n",
    "    print(res)\n",
    "    return max(res, key=res.get), max(res.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 0.46317096004832026, 3: 0.3214713024869174, 4: 0.38160981543092376, 5: 0.3480747805114875, 6: 0.33372943972323865, 7: 0.3320776409159453, 8: 0.34085260400997613, 9: 0.3080195268450422, 10: 0.3057765208844841}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 0.46317096004832026)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = silhouette_calc(df_norm, 10)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot silhouettes for max\n",
    "kmeans = KMeans(n_clusters=res[0], max_iter=500)\n",
    "kmeans.fit(df_norm)\n",
    "clusters = kmeans.predict(df_norm)\n",
    "plot_silhouettes(df_norm, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "After applying our function to test for the best silhouette score between 2 and 10 clusters, we get a value of 2 with a silhouette score of .463. Although we're only using 2 clusters, the silhouette score is higher, indicating that we do a better job at classifying the observations within the same class as well as separating the two classes from one another. Since we are supposed to have 7 classes, I'm guessing that there are some outliers/noise that is causing the k-means method to incorrectly classify these points. If the clusters aren't spherically shaped, k-means typically has trouble, so performing some dimensionality reduction in the next couple steps might prove to be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.)\n",
    "Perform PCA on the normalized image data matrix. You may use the linear algebra package in Numpy or the Decomposition module in scikit-learn (the latter is much more efficient). Analyze the principal components to determine the number, r, of PCs needed to capture at least 95% of variance in the data. Provide a Scree plot of PC variances. Then use these r components as features to transform the data into a reduced dimension space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pca, fit to df_norm\n",
    "pca = decomposition.PCA()\n",
    "df_trans = pca.fit_transform(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69  0.53  0.25 ... -0.    0.    0.  ]\n",
      " [-0.67  0.51  0.34 ...  0.   -0.   -0.  ]\n",
      " [-0.71  0.77 -0.16 ...  0.    0.    0.  ]\n",
      " ...\n",
      " [-0.51 -0.13 -0.08 ... -0.    0.    0.  ]\n",
      " [-0.48 -0.09 -0.16 ... -0.    0.   -0.  ]\n",
      " [-0.44 -0.11 -0.05 ... -0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(df_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61 0.13 0.1  0.05 0.04 0.02 0.02 0.02 0.01 0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "#explained var by component\n",
    "np.set_printoptions(suppress=True, precision=2, linewidth=120)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Percentage of Variance')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#scree plot\n",
    "varPercentage = pca.explained_variance_ratio_*100\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(range(19), varPercentage[:], marker='^')\n",
    "plt.title('Scree Plot - Components vs % Var Explained')\n",
    "plt.xlabel('Principal Component Number')\n",
    "plt.ylabel('Percentage of Variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.607142339685333\n",
      "2 0.7391121320168929\n",
      "3 0.840349861425619\n",
      "4 0.8857852534332584\n",
      "5 0.9212588648109569\n",
      "6 0.9411392197960623\n",
      "7 0.9600589227704958\n",
      "8 0.9762130108194517\n",
      "9 0.9868690193362032\n",
      "10 0.9939823945149533\n",
      "11 0.9979044297671411\n",
      "12 0.9994794328616068\n",
      "13 0.9999685835864895\n",
      "14 0.9999999999999993\n",
      "15 0.9999999999999996\n",
      "16 0.9999999999999997\n",
      "17 0.9999999999999998\n",
      "18 0.9999999999999999\n",
      "19 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "#calc how many components to get >=.95 var explained\n",
    "s = 0\n",
    "for i in range(len(pca.explained_variance_ratio_)):\n",
    "    s += pca.explained_variance_ratio_[i]\n",
    "    print(i+1,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.69,  0.53,  0.25, ..., -0.08,  0.05, -0.05],\n",
       "       [-0.67,  0.51,  0.34, ..., -0.04,  0.06, -0.04],\n",
       "       [-0.71,  0.77, -0.16, ..., -0.17,  0.04, -0.06],\n",
       "       ...,\n",
       "       [-0.51, -0.13, -0.08, ..., -0.03, -0.03, -0.11],\n",
       "       [-0.48, -0.09, -0.16, ...,  0.  , -0.  , -0.09],\n",
       "       [-0.44, -0.11, -0.05, ...,  0.02, -0.21,  0.15]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7 components needed for >=.95 var explained, transform df to reduced 7 features\n",
    "dftrans_reduced = df_trans[:,:7]\n",
    "dftrans_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.)\n",
    "Perform Kmeans again, but this time on the lower dimensional transformed data. Then compare Silhouette values as well as completeness and Homogeneity values of the new clusters. Compare these results with those obtained on the full data in part b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kmeans, lower dim data\n",
    "kmeans2 = KMeans(n_clusters=7, max_iter=500)\n",
    "kmeans2.fit(dftrans_reduced)\n",
    "clusters2 = kmeans2.predict(dftrans_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35970957979807067"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#silhouette mean\n",
    "silhouettes = metrics.silhouette_samples(dftrans_reduced, clusters2)\n",
    "silhouettes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "plot_silhouettes(dftrans_reduced, clusters2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness Score: 0.6115749269916771\n",
      "Homogenity Score: 0.6099736092174177\n"
     ]
    }
   ],
   "source": [
    "#compute homogenity and completeness scores\n",
    "print(f\"Completeness Score: {completeness_score(df_target[1],clusters2)}\")\n",
    "print(f\"Homogenity Score: {homogeneity_score(df_target[1],clusters2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Comparing our scores from part b.), we get .3597 vs .3320 for our silhouette mean scores, .6116 vs .6132 for completeness scores, and .6100 vs .6115 for our homogenity score. So overall, our silhouette mean did improve slightly in the reduced dimension dataset, but our overall completeness and homogenity scores remain the same. Reducing the dimensions on our dataset helped elimnate some of the noise, which resulted in a better silhouette mean score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem #2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.)\n",
    "Load in the joke ratings data and the joke text data into appropriate data structures. Use the \"recommend\" function to provide top 5 joke recommendations for users with id 4 using both Pearson and cosine similarity measures. Note the differences. Use the standard item-based collaborative filtering (based on the rating prediction function \"standEst\"). Next, find the top 5 recommendations for user with id 25 only with Pearson similarity using both the standard estimator and the SVD-based version (using \"svdEst\" as the prediction engine) to generate these recommendations. Note the differences. When outputting recommendations, you should show both the id and the text of the recommended jokes (in decreasing order of predicted rating) as well as the predicted ratings for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itemBasedRec as ibr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      0      1      2      3      4      5      6      7      8      9   ...  \\\n",
       " 0   3.18  19.79   1.34   2.84   3.48   2.50   1.15  15.17   2.02   6.24  ...   \n",
       " 1  15.08  10.71  17.36  15.37   8.62   1.34  10.27   5.66  19.88  20.22  ...   \n",
       " 2   0.00   0.00   0.00   0.00  20.03  20.27  20.03  20.27   0.00   0.00  ...   \n",
       " 3   0.00  19.35   0.00   0.00  12.80  19.16   8.18  17.21   0.00  12.84  ...   \n",
       " 4  19.50  15.61   6.83   5.61  12.36  12.60  18.04  15.61  10.56  16.73  ...   \n",
       " \n",
       "       90     91     92     93     94     95     96     97     98     99  \n",
       " 0  13.82   0.00   0.00   0.00   0.00   0.00   5.37   0.00   0.00   0.00  \n",
       " 1  13.82   6.05  10.71  18.86  10.81   8.86  14.06  11.34   6.68  12.07  \n",
       " 2   0.00   0.00   0.00  20.08   0.00   0.00   0.00   0.00   0.00   0.00  \n",
       " 3   0.00   0.00   0.00  11.53   0.00   0.00   0.00   0.00   0.00   0.00  \n",
       " 4  16.19  16.58  15.27  16.19  16.73  12.55  14.11  17.55  12.80  12.60  \n",
       " \n",
       " [5 rows x 100 columns],\n",
       " (1000, 100))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in data\n",
    "jokes_df = pd.read_csv('modified_jester_data.csv', header=None)\n",
    "jokes_mat = np.mat(jokes_df)\n",
    "jokes_df.head(), jokes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                   1\n",
       " 0  A man visits the doctor. The doctor says \"I ha...\n",
       " 1  This couple had an excellent relationship goin...\n",
       " 2  Q. What's 200 feet long and has 4 teeth? A. Th...\n",
       " 3  Q. What's the difference between a man and a t...\n",
       " 4  Q. What's O. J. Simpson's Internet address? A....,\n",
       " (100, 1))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in joke ids\n",
    "joke_ids = pd.read_csv('jokes.csv',header=None)\n",
    "joke_ids = pd.DataFrame(joke_ids[1])\n",
    "joke_ids.head(), joke_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(71, 14.413443009309447),\n",
       " (75, 14.397311198445264),\n",
       " (79, 14.382511887413443),\n",
       " (78, 14.356160763938075),\n",
       " (72, 14.334361485417928)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ibr.recommend(jokes_mat, 4, 5, ibr.pearsonSim, ibr.standEst)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function\n",
    "def rec_jokes(M, user, N=3, simMeas=ibr.pearsonSim, estMethod=ibr.standEst):\n",
    "    '''outputs format with joke description using recommend function'''\n",
    "    a = ibr.recommend(M, user, N, simMeas, estMethod)\n",
    "    \n",
    "    #fix formatting\n",
    "    a = pd.DataFrame(a)\n",
    "    a.index = a[0]\n",
    "    a = pd.DataFrame(a[1])\n",
    "    a['Joke Description'] = joke_ids.iloc[a.index]\n",
    "    a.columns = [['Predicted Rating', 'Joke Description']]\n",
    "    return a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Predicted Rating</th>\n",
       "      <th>Joke Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>14.41</td>\n",
       "      <td>On the first day of college the Dean addressed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>14.40</td>\n",
       "      <td>There once was a man and a woman that both  go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>14.38</td>\n",
       "      <td>Hillary Bill Clinton and the Pope are sitting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>14.36</td>\n",
       "      <td>Q: Ever wonder why the IRS calls it Form 1040?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>14.33</td>\n",
       "      <td>Q: What is the difference between George  Wash...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted Rating                                   Joke Description\n",
       "0                                                                     \n",
       "71            14.41  On the first day of college the Dean addressed...\n",
       "75            14.40  There once was a man and a woman that both  go...\n",
       "79            14.38  Hillary Bill Clinton and the Pope are sitting ...\n",
       "78            14.36  Q: Ever wonder why the IRS calls it Form 1040?...\n",
       "72            14.33  Q: What is the difference between George  Wash..."
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user id 4, top 5 jokes, pearson sim, standard est\n",
    "a = rec_jokes(jokes_mat, 4, 5, ibr.pearsonSim, ibr.standEst)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Predicted Rating</th>\n",
       "      <th>Joke Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>14.29</td>\n",
       "      <td>On the first day of college the Dean addressed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>14.29</td>\n",
       "      <td>There once was a man and a woman that both  go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>14.29</td>\n",
       "      <td>Hillary Bill Clinton and the Pope are sitting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>14.29</td>\n",
       "      <td>Q: Ever wonder why the IRS calls it Form 1040?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>14.29</td>\n",
       "      <td>At a recent Sacramento PC Users Group meeting ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted Rating                                   Joke Description\n",
       "0                                                                     \n",
       "71            14.29  On the first day of college the Dean addressed...\n",
       "75            14.29  There once was a man and a woman that both  go...\n",
       "79            14.29  Hillary Bill Clinton and the Pope are sitting ...\n",
       "78            14.29  Q: Ever wonder why the IRS calls it Form 1040?...\n",
       "70            14.29  At a recent Sacramento PC Users Group meeting ..."
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user id 4, top 5 jokes, cosine sim, standard est\n",
    "a = rec_jokes(jokes_mat, 4, 5, ibr.cosineSim, ibr.standEst)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([71, 75, 79, 78, 72], dtype='int64', name=0)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Predicted Rating</th>\n",
       "      <th>Joke Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>15.32</td>\n",
       "      <td>Q: What's the difference between greeting a Qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>15.32</td>\n",
       "      <td>On the first day of college the Dean addressed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>15.32</td>\n",
       "      <td>Age and Womanhood1. Between the ages of 13 and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>15.30</td>\n",
       "      <td>What a woman says:\"This place is a mess!  C'mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>15.29</td>\n",
       "      <td>Early one morning a mother went to her sleepin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted Rating                                   Joke Description\n",
       "0                                                                     \n",
       "99            15.32  Q: What's the difference between greeting a Qu...\n",
       "71            15.32  On the first day of college the Dean addressed...\n",
       "97            15.32  Age and Womanhood1. Between the ages of 13 and...\n",
       "82            15.30  What a woman says:\"This place is a mess!  C'mo...\n",
       "91            15.29  Early one morning a mother went to her sleepin..."
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user id 25, top 5 jokes, pearson sim, standard est\n",
    "a = rec_jokes(jokes_mat, 25, 5, ibr.pearsonSim, ibr.standEst)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Predicted Rating</th>\n",
       "      <th>Joke Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.28</td>\n",
       "      <td>Q. What's the difference between a man and a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>15.24</td>\n",
       "      <td>Hillary Bill Clinton and the Pope are sitting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>15.21</td>\n",
       "      <td>Q: What is the difference between George  Wash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>15.19</td>\n",
       "      <td>On the first day of college the Dean addressed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>15.18</td>\n",
       "      <td>Q: What's the difference between greeting a Qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted Rating                                   Joke Description\n",
       "0                                                                     \n",
       "3             15.28  Q. What's the difference between a man and a t...\n",
       "79            15.24  Hillary Bill Clinton and the Pope are sitting ...\n",
       "72            15.21  Q: What is the difference between George  Wash...\n",
       "71            15.19  On the first day of college the Dean addressed...\n",
       "99            15.18  Q: What's the difference between greeting a Qu..."
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user id 25, top 5 jokes, pearson sim, svd est\n",
    "a = rec_jokes(jokes_mat, 25, 5, ibr.pearsonSim, ibr.svdEst)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"Q. What's the difference between a man and a toilet? A. A toilet doesn't follow you around after you use it.\"],\n",
       "       ['Hillary Bill Clinton and the Pope are sitting together on an airplane. Bill says \"I could throw one thousand dollar bill out of this plane and make one person very happy.\"Hillary says \"I could throw 10 hundred dollar bills out of the plane and make 10 people very happy.\"The Pope chips in and says \"I could throw Bill out of the airplane and make the whole country happy.\"'],\n",
       "       [\"Q: What is the difference between George  Washington Richard Nixon and Bill Clinton? A: Washington couldn't tell a lie Nixon couldn't   tell the truth andClinton doesn't know the difference.\"],\n",
       "       ['On the first day of college the Dean addressed the students pointing out some of the rules:\"The female dormitory will be out-of-bounds for all male students and the male dormitory to the female students. Anybody caught breaking this rule will be fined $20 the first time.\" He continued \"Anybody caught breaking this rule the second time will be fined $60. Being caught a third time will cost you a fine of $180. Are there any questions ?\"At this point a male student in the crowd inquired:\"How much for a season pass ?\"'],\n",
       "       [\"Q: What's the difference between greeting a Queen and greeting thePresident of the United  States?A: You only have to get on one knee to greet the queen.\"]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(a[['Joke Description']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Looking at user id 4, we see that both the pearson and cosine similarities classify the first 4 jokes the same, but they differ on the last joke (joke 72 vs joke 70). Looking at the predicted rating, we see that the values for the cosine similarity are very close to each other, while pearson is spread further apart. The jokes themselves seem related to government in both categories.\n",
    "\n",
    "Looking at user id 25, we see pretty different results comparing the standEst and svdEst item-based collaborative filters. The standEst values seem to have jokes relating to women, while svdEst seems to have a mix of both government related jokes and women related jokes. The ratings are more tightly knit for the standEst compared to the svdEst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.)\n",
    "Complete the definition for the function \"test\". This function iterates over all users and for each performs evaluation (by calling the provided \"cross_validate_user\" function) and returns the error information necessary to compute Mean Absolute Error (MAE). Use this function to perform evaluation (with 20% test-ratio for each user) comparing MAE results using the rating prediction function \"standEst\" with results using the \"svdEst\" prediction function (in both cases using Pearson similarity measure. Note that this may take several minutes depending on your computational environment. [Note: See comments provided in the module for hints on accomplishing these tasks.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71.11723843611041, 18)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = ibr.cross_validate_user(jokes_mat, 4, .2)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataMat, test_ratio, estMethod, simMeas=ibr.pearsonSim):\n",
    "    '''for each user, perform MAE cross validation w/ 20% test ratio and store it in a df to calc ttl MAE'''\n",
    "    #create df of correct shape of ones\n",
    "    res = pd.DataFrame(np.ones((np.shape(dataMat)[0],2), dtype=float),columns=['Error','Count'])\n",
    "    \n",
    "    for i in range(dataMat.shape[0]):\n",
    "        \n",
    "        #perform cv\n",
    "        cv = ibr.cross_validate_user(dataMat, i, test_ratio, estMethod, simMeas)\n",
    "        #store cv values into df\n",
    "        res.iloc[i] = res.iloc[i] * cv\n",
    "    \n",
    "    return res['Error'].sum() / res['Count'].sum()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7124208021257803"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#20% test using standard estimator\n",
    "a = test(jokes_mat, .2, ibr.standEst)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6469942826788713"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#20% test using svd estimator\n",
    "b = test(jokes_mat, .2, ibr.svdEst)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "After creating the test function and utilizing it to calculate a total MAE across all users for our standard and svd estimator, we see that our standard estimator was slightly worse due to having a higher MAE value. This could be because the SVD reduces the dimensionality of our matrix (hard coded to 4), which may reduce the noise going on in the total number of dimensions. The MAE tells us that using 20% of our data as test data, we were on average off on our user predicted ratings by 3.71 and 3.65 in the standard and svd estimator respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.)\n",
    "Write a new function \"print_most_similar_jokes\" which outputs the most similar jokes (based on user ratings) to a specified query joke. You function should take as input the joke ratings data, a query joke id, a parameter k for the number similar jokes, and a similarity metric function. It should output the text of the query joke as well as the texts of the top k most similar jokes in decreasing order of similarity (you should also provide the similarity values). Test your function as follows:\n",
    "\n",
    "     * Show the top 3 most similar jokes to joke with id 9 using Pearson similarity.\n",
    "     * Show the top 3 most similar jokes to Joke with id 9 using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 3.18, 15.08,  0.  , ..., 16.58,  3.67,  9.88],\n",
       "        [19.79, 10.71,  0.  , ..., 16.63,  4.45, 11.73],\n",
       "        [ 1.34, 17.36,  0.  , ..., 15.85,  3.67,  9.16],\n",
       "        ...,\n",
       "        [ 0.  , 11.34,  0.  , ...,  0.  ,  3.77,  0.  ],\n",
       "        [ 0.  ,  6.68,  0.  , ...,  0.  ,  3.77,  0.  ],\n",
       "        [ 0.  , 12.07,  0.  , ...,  0.  ,  3.28,  0.  ]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes_mat_T = jokes_mat.T\n",
    "jokes_mat_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_joke_sim(dataMat, joke_id, simMeas):\n",
    "    '''calculates the similarity of a given joke_id to all other jokes'''\n",
    "    \n",
    "    res = pd.DataFrame(np.ones((np.shape(dataMat)[1],1), dtype=float),columns=['Sim'])\n",
    "    \n",
    "    for i in range(dataMat.shape[1]):\n",
    "        \n",
    "        sim = simMeas(dataMat[:,i], dataMat[:,joke_id])\n",
    "        \n",
    "        res.iloc[i] = res.iloc[i] * sim\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_similar_jokes(dataMat, joke_id, k, simMeas):\n",
    "    '''finds the top k most similar jokes to a given joke using a similarity measure'''\n",
    "    \n",
    "    #calculate joke_id similarity between all jokes\n",
    "    res = calc_joke_sim(dataMat, joke_id, simMeas)\n",
    "    #add joke description to res\n",
    "    res['Joke Description'] = joke_ids.iloc[res.index]\n",
    "    #sort results\n",
    "    res.sort_values(by=['Sim'], inplace=True, ascending=False)\n",
    "    \n",
    "    ares = np.array(res)\n",
    "    \n",
    "    #selected joke\n",
    "    print('Selected Joke:')\n",
    "    print(f\"Joke ID: {joke_id}\\nJoke: {ares[0,1]}\")\n",
    "    print()\n",
    "    print(f\"Top {k} Recommended jokes are: \")\n",
    "    #print k most similar jokes for given joke\n",
    "    for i in range(k):\n",
    "        print(f\"Joke {i+1} Similarity Value: {ares[i+1,0]}\")\n",
    "        print(f\"Joke {i+1} Description: {ares[i+1,1]}\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Joke:\n",
      "Joke ID: 9\n",
      "Joke: Two cannibals are eating a clown one turns to other and says: \"Does this taste funny to you? \n",
      "\n",
      "Top 3 Recommended jokes are: \n",
      "Joke 1 Similarity Value: 0.7613547766060571\n",
      "Joke 1 Description: A duck walks into a pharmacy and asks for a condom. The pharmacist says\"Would you like me to stick that on your bill?\"The duck says: \"What kind of duck do you think I am!\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Joke 2 Similarity Value: 0.7584095690232999\n",
      "Joke 2 Description: Q. What do a hurricane a tornado and a redneck divorce all have in common? A. Someone's going to lose their trailer...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Joke 3 Similarity Value: 0.7540592776837659\n",
      "Joke 3 Description: A woman has twins and gives them up for adoption.  One of them goes to a family in Egypt and is named \"Amal.\"  The other goes to a  family in Spain; they name him \"Juan.\"  Years later Juan sends a picture of himself to his mom.  Upon receiving the picture she tells her husband that she wishes she also had a picture of Amal.  Her husband responds \"But they are twins-if you've seen Juan you've seen   Amal.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#top 3 jokes for joke_id 9 using pearsonSim\n",
    "res = print_most_similar_jokes(jokes_mat, 9, 3, ibr.pearsonSim)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Joke:\n",
      "Joke ID: 9\n",
      "Joke: Two cannibals are eating a clown one turns to other and says: \"Does this taste funny to you? \n",
      "\n",
      "Top 3 Recommended jokes are: \n",
      "Joke 1 Similarity Value: 0.9290069063401065\n",
      "Joke 1 Description: Q. What do a hurricane a tornado and a redneck divorce all have in common? A. Someone's going to lose their trailer...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Joke 2 Similarity Value: 0.9283595009905077\n",
      "Joke 2 Description: May I take your order? the waiter asked. \"Yes how do you prepare your chickens?\" \"Nothing special sir\" he replied. \"We just tell them straight out that they're going to die.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Joke 3 Similarity Value: 0.9268826687157665\n",
      "Joke 3 Description: A duck walks into a pharmacy and asks for a condom. The pharmacist says\"Would you like me to stick that on your bill?\"The duck says: \"What kind of duck do you think I am!\"\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#top 3 jokes for joke_id 9 using cosineSim\n",
    "res2 = print_most_similar_jokes(jokes_mat, 9, 3, ibr.cosineSim)\n",
    "res2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "After creating our joke similarity function, I calculated the Top 3 recommended jokes for joke_id 9 utilizing pearson and cosine similarity. For pearson, we see that the similarity values are significantly lower than those for cosine. They both selected two of the same jokes (in different order) and one joke different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.)\n",
    "The implementation of item-based collaborative filtering provided in the module is not scalable since for each prediction it attempts to compute pairwise similarities among all items. Develop your own item-based collaborative filtering recommender that uses a model-based approach (separating the training and the prediction tasks). In the training component, item-item similarities for all pairs of items are computed and stored in an appropriate data structure such as a pairwise similarity matrix. Your training function should be able to use different similarity functions (passed as a parameter) including cosine Similarity or Pearson correlation. The prediction (or estimation) function should take as parameters a target user, an item, a value of k, and the similarities matrix computed in the training phase. It should then return the predicted rating on the target item for the target user. The predicted rating should be the weighted average of the target user's ratings on the k most similar items to the target item (obtained from the similarity matrix). Demonstrate that your function works by computing predicted ratings for users 4 and 25, using k = 10, on top two items recommended to each user on part a (using both Pearson and cosine similarities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute training function\n",
    "def r_train(dataMat, simMeas):\n",
    "    '''returns the pairwise similarity matrix for a given data matrix'''\n",
    "    n = dataMat.shape[1]\n",
    "    res = pd.DataFrame(np.ones((n, n), dtype=float), columns=range(n))\n",
    "    #return res\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        #calculate ith joke similarity vector\n",
    "        sim = calc_joke_sim(dataMat, i, simMeas)\n",
    "        \n",
    "        #update ith joke in result\n",
    "        res[i] = res[i] * sim['Sim']\n",
    "    \n",
    "    return np.mat(res)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test/prediction function\n",
    "def r_test(dataMat, target_user, item, k, simMat):\n",
    "    '''Returns the predicted rating on the target item for the target user'''\n",
    "    #get k sims from simMat\n",
    "    simMat = pd.DataFrame(simMat)\n",
    "    topJokes = simMat.sort_values(by=[item], ascending=False)\n",
    "    simWeights = np.array(topJokes)[1:k+1,0]\n",
    "    #return simWeights\n",
    "    \n",
    "    #get k ratings from dataMat\n",
    "    r = pd.DataFrame(jokes_mat[target_user])\n",
    "    r = r.T\n",
    "    ratings = r.iloc[topJokes[1:k+1].index]\n",
    "    weightedAvg = (simWeights * ratings.T).T.sum() / k\n",
    "    \n",
    "    return weightedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.  , 0.79, 0.78, ..., 0.64, 0.64, 0.65],\n",
       "        [0.79, 1.  , 0.73, ..., 0.62, 0.6 , 0.63],\n",
       "        [0.78, 0.73, 1.  , ..., 0.65, 0.64, 0.68],\n",
       "        ...,\n",
       "        [0.64, 0.62, 0.65, ..., 1.  , 0.82, 0.88],\n",
       "        [0.64, 0.6 , 0.64, ..., 0.82, 1.  , 0.84],\n",
       "        [0.65, 0.63, 0.68, ..., 0.88, 0.84, 1.  ]])"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train your data matrix, pearson sim\n",
    "r = r_train(jokes_mat, ibr.pearsonSim)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.57\n",
       "dtype: float64"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test for user 4, k=10, item 71\n",
    "res = r_test(jokes_mat, 4, 71, 10, r)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.57\n",
       "dtype: float64"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test for user 4, k=10, item 75\n",
    "res = r_test(jokes_mat, 4, 75, 10, r)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test for user 25, k=10, item 99\n",
    "res = r_test(jokes_mat, 25, 99, 10, r)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.83\n",
       "dtype: float64"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test for user 25, k=10, item 71\n",
    "res = r_test(jokes_mat, 25, 71, 10, r)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.  , 0.92, 0.91, ..., 0.79, 0.8 , 0.79],\n",
       "        [0.92, 1.  , 0.89, ..., 0.78, 0.78, 0.79],\n",
       "        [0.91, 0.89, 1.  , ..., 0.79, 0.79, 0.8 ],\n",
       "        ...,\n",
       "        [0.79, 0.78, 0.79, ..., 1.  , 0.88, 0.92],\n",
       "        [0.8 , 0.78, 0.79, ..., 0.88, 1.  , 0.89],\n",
       "        [0.79, 0.79, 0.8 , ..., 0.92, 0.89, 1.  ]])"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train matrix, cosineSim\n",
    "r = r_train(jokes_mat, ibr.cosineSim)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5.74\n",
       "dtype: float64"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test for user 4, k=10, item 71\n",
    "res = r_test(jokes_mat, 4, 71, 10, r)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5.81\n",
       "dtype: float64"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test for user 4, k=10, item 75\n",
    "res = r_test(jokes_mat, 4, 75, 10, r)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test for user 25, k=10, item 99\n",
    "res = r_test(jokes_mat, 25, 99, 10, r)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.04\n",
       "dtype: float64"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test for user 25, k=10, item 71\n",
    "res = r_test(jokes_mat, 25, 71, 10, r)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "For this part, I created a train function, which took in the jokes matrix and created a pairwise matrix of similarity scores based on the similarity function used. From here, I created a test function and used that to capture the estimated rating values for each target user/item combination with k=10 similar jokes. My rating values are very low, and I had trouble figuring out how to exclude the 0 ratings from users into my test model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
